services:
  vernemq:
    restart: always
    container_name: vernemq-mqtt-broker
    image: vernemq/vernemq:latest
    ports:
      - "1883:1883" # MQTT port
    environment:
      - DOCKER_VERNEMQ_ACCEPT_EULA=yes
      - DOCKER_VERNEMQ_ALLOW_ANONYMOUS=on
      - DOCKER_VERNEMQ_LOG__CONSOLE__LEVEL=warning
      - DOCKER_VERNEMQ_PLUGINS__vmq_acl=on
      - DOCKER_VERNEMQ_VMQ_ACL__ACL_FILE=/etc/vernemq/vmq.acl
    volumes:
      - ./vernemq-acl:/etc/vernemq

  testserver:
    build:
      context: ../../..
      dockerfile: ./internal/test/integration/components/gomqtt/Dockerfile
    image: hatest-testserver-go-mqtt
    ports:
      - "${TEST_SERVICE_PORTS}"
    environment:
      - MQTT_BROKER=vernemq:1883
      - MQTT_TOPIC=test/topic
      - MQTT_QOS=1
    depends_on:
      otelcol:
        condition: service_started
      vernemq:
        condition: service_started
      jaeger:
        condition: service_started

  obi:
    build:
      context: ../../..
      dockerfile: ./internal/test/integration/components/ebpf-instrument/Dockerfile
    volumes:
      - ./configs/:/configs
      - ./system/sys/kernel/security:/sys/kernel/security
      - ../../../testoutput:/coverage
      - ../../../testoutput/run-mqtt:/var/run/beyla
    image: hatest-obi
    privileged: true # in some environments (not GH Pull Requests) you can set it to false and then cap_add: [ SYS_ADMIN ]
    network_mode: "service:testserver"
    pid: "service:testserver"
    environment:
      OTEL_EBPF_CONFIG_PATH: "/configs/obi-config.yml"
      GOCOVERDIR: "/coverage"
      OTEL_EBPF_TRACE_PRINTER: "text"
      OTEL_EBPF_DISCOVERY_POLL_INTERVAL: 500ms
      OTEL_EBPF_EXECUTABLE_PATH: "${OTEL_EBPF_EXECUTABLE_PATH}"
      OTEL_EBPF_SERVICE_NAMESPACE: "integration-test"
      OTEL_EBPF_METRICS_INTERVAL: "10ms"
      OTEL_EBPF_BPF_BATCH_TIMEOUT: "10ms"
      OTEL_EBPF_OTLP_TRACES_BATCH_TIMEOUT: "1ms"
      OTEL_EBPF_LOG_LEVEL: "DEBUG"
      OTEL_EBPF_BPF_DEBUG: "TRUE"
      OTEL_EBPF_HOSTNAME: "beyla"
      OTEL_EBPF_BPF_HTTP_REQUEST_TIMEOUT: "5s"
      OTEL_EBPF_PROCESSES_INTERVAL: "100ms"
      OTEL_EBPF_TRACES_INSTRUMENTATIONS: "*"
      OTEL_EBPF_METRICS_INSTRUMENTATIONS: "*"
      OTEL_EBPF_METRICS_FEATURES: "application"
      OTEL_EBPF_PROTOCOL_DEBUG_PRINT: "true"
    depends_on:
      testserver:
        condition: service_started

  # OpenTelemetry Collector
  otelcol:
    image: otel/opentelemetry-collector-contrib:0.118.0@sha256:3f6274fe609da4f9964fbc2ef36b83d08d47964fbb11629251393590d3924072
    container_name: otel-col
    deploy:
      resources:
        limits:
          memory: 125M
    restart: unless-stopped
    command: ["--config=/etc/otelcol-config/otelcol-config.yml"]
    volumes:
      - ./configs/:/etc/otelcol-config
    ports:
      - "4317" # OTLP over gRPC receiver
      - "4318:4318" # OTLP over HTTP receiver
      - "9464" # Prometheus exporter
      - "8888" # metrics endpoint
    depends_on:
      prometheus:
        condition: service_started

  # Prometheus
  prometheus:
    image: quay.io/prometheus/prometheus:v2.55.1@sha256:2659f4c2ebb718e7695cb9b25ffa7d6be64db013daba13e05c875451cf51b0d3
    container_name: prometheus
    command:
      - --config.file=/etc/prometheus/prometheus-config.yml
      - --web.enable-lifecycle
      - --web.route-prefix=/
      - --log.level=warn
    volumes:
      - ./configs/:/etc/prometheus
    ports:
      - "9090:9090"

  jaeger:
    image: jaegertracing/all-in-one:1.60@sha256:4fd2d70fa347d6a47e79fcb06b1c177e6079f92cba88b083153d56263082135e
    ports:
      - "16686:16686" # Query frontend
      - "4317" # OTEL GRPC traces collector
      - "4318" # OTEL HTTP traces collector
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - LOG_LEVEL=warn
